{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIupDNv_Uwhx",
    "outputId": "cefbe590-ff13-44e3-a6cf-c44549fa3966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 29 09:44:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLKLO2KUk9X"
   },
   "source": [
    "### *Install/Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6wu_y-xzVcsw"
   },
   "outputs": [],
   "source": [
    "%pip install -q \"monai[nibabel, tqdm]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BEkgEEd_Uk1S"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "import monai\n",
    "from monai.data import Dataset, CacheDataset, DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    CastToTyped,\n",
    "    LoadNiftid,\n",
    "    Orientationd,\n",
    "    RandAffined,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandGaussianNoised,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    SpatialPadd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RzDnnf2nXand"
   },
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "batch_size = 2\n",
    "\n",
    "keys = ('image', 'label')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xdyyyd4rVpxC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH1DKATBVs4h"
   },
   "source": [
    "### *Load data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yy8pdJTKVsoc"
   },
   "outputs": [],
   "source": [
    "DIR = './COVID-19-20/Train'\n",
    "\n",
    "images = sorted(glob.glob(os.path.join(DIR, '*_ct.nii.gz')))\n",
    "labels = sorted(glob.glob(os.path.join(DIR, '*_seg.nii.gz')))\n",
    "n_train = int(train_split * len(images)) + 1\n",
    "n_val = int(len(images) - n_train)\n",
    "\n",
    "train_data = [{keys[0]: img, keys[1]: seg} for img,seg in zip(images[:n_train], labels[:n_train])]\n",
    "val_data = [{keys[0]: img, keys[1]: seg} for img,seg in zip(images[-n_val:], labels[-n_val:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aUvU6G4JVsBn"
   },
   "outputs": [],
   "source": [
    "def get_transforms(mode='train', keys=('image', 'label')):\n",
    "\n",
    "    if mode == 'train':\n",
    "        transform = Compose([\n",
    "                             LoadNiftid(keys),\n",
    "                             AddChanneld(keys),\n",
    "                             Orientationd(keys, axcodes = \"LPS\"),\n",
    "                             Spacingd(keys, pixdim=(1.25, 1.25, 3.0), mode=(\"bilinear\", \"nearest\")[: len(keys)]),\n",
    "                             ScaleIntensityRanged(keys[0], a_min=-1000.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "                             SpatialPadd(keys, spatial_size=(192, 192, -1), mode=\"reflect\"),          # ensure at least 192x192\n",
    "                             RandAffined(keys,\n",
    "                                         prob=0.15,\n",
    "                                         rotate_range=(-0.05, 0.05), scale_range=(-0.1, 0.1),\n",
    "                                         mode=(\"bilinear\", \"nearest\"),\n",
    "                                         as_tensor_output=False),\n",
    "                             RandCropByPosNegLabeld(keys, label_key=keys[1], spatial_size=(192, 192, 16), num_samples=4),\n",
    "                             RandGaussianNoised(keys[0], prob=0.15, std=0.01),\n",
    "                             RandFlipd(keys, spatial_axis=0, prob=0.5),\n",
    "                             RandFlipd(keys, spatial_axis=1, prob=0.5),\n",
    "                             RandFlipd(keys, spatial_axis=2, prob=0.5),\n",
    "                             CastToTyped(keys, dtype=(np.float32, np.uint8)),\n",
    "                             ToTensord(keys)\n",
    "                            ])\n",
    "    if mode == 'val':\n",
    "        transform = Compose([\n",
    "                             LoadNiftid(keys),\n",
    "                             AddChanneld(keys),\n",
    "                             Orientationd(keys, axcodes = \"LPS\"),\n",
    "                             Spacingd(keys, pixdim=(1.25, 1.25, 3.0), mode=(\"bilinear\", \"nearest\")[: len(keys)]),\n",
    "                             ScaleIntensityRanged(keys[0], a_min=-1000.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "                             SpatialPadd(keys, spatial_size=(192, 192, -1), mode=\"reflect\"),          # ensure at least 192x192 if not then apply padd\n",
    "                             RandCropByPosNegLabeld(keys, label_key=keys[1], spatial_size=(192, 192, 16), num_samples=4),\n",
    "                             CastToTyped(keys, dtype=(np.float32, np.uint8)),\n",
    "                             ToTensord(keys)\n",
    "                            ])\n",
    "    if mode == 'infer':\n",
    "        transform = Compose([\n",
    "                             LoadNiftid(keys),\n",
    "                             AddChanneld(keys),\n",
    "                             Orientationd(keys, axcodes = \"LPS\"),\n",
    "                             Spacingd(keys, pixdim=(1.25, 1.25, 3.0), mode=(\"bilinear\", \"nearest\")[: len(keys)]),\n",
    "                             ScaleIntensityRanged(keys[0], a_min=-1000.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "                             CastToTyped(keys, dtype=(np.float32,)),\n",
    "                             ToTensord(keys)\n",
    "                            ])\n",
    "    return transform\n",
    "\n",
    "train_transforms = get_transforms('train', keys)\n",
    "val_transforms = get_transforms('val', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "97JXdK-qWNd_"
   },
   "outputs": [],
   "source": [
    "# Create DataSet\n",
    "\n",
    "train_ds = Dataset(data = train_data,\n",
    "                   transform = train_transforms)\n",
    "val_ds = Dataset(data = val_data,\n",
    "                 transform = val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "atF5zB_gWNYe"
   },
   "outputs": [],
   "source": [
    "# Set DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=batch_size)\n",
    "val_loader = DataLoader(val_ds,\n",
    "                        batch_size=batch_size)         # image-level batch to the sliding window method, not the window-level batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxTeVV2eWQl2",
    "outputId": "cd009675-f541-4663-f786-d84ccd080a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Info:\n",
      "shape of images : torch.Size([8, 1, 192, 192, 16])\n",
      "shape of labels : torch.Size([8, 1, 192, 192, 16])\n",
      "\n",
      "Validation data Info:\n",
      "shape of images : torch.Size([8, 1, 192, 192, 16])\n",
      "shape of labels : torch.Size([8, 1, 192, 192, 16])\n"
     ]
    }
   ],
   "source": [
    "# explore DataLoader\n",
    "\n",
    "print('Training data Info:')\n",
    "dataiter = iter(train_loader)\n",
    "data = dataiter.next()\n",
    "images,labels = data['image'],data['label']\n",
    "print(\"shape of images : {}\".format(images.shape))\n",
    "print(\"shape of labels : {}\".format(labels.shape))\n",
    "\n",
    "print('\\nValidation data Info:')\n",
    "dataiter = iter(val_loader)\n",
    "data = dataiter.next()\n",
    "images,labels = data['image'],data['label']\n",
    "print(\"shape of images : {}\".format(images.shape))\n",
    "print(\"shape of labels : {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "YJDiug9uWQjE"
   },
   "outputs": [],
   "source": [
    "del dataiter, data, images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THyGRQTgY2r1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXKbirCGUrfE"
   },
   "source": [
    "### *Create Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UpqbGNaHUvCm"
   },
   "outputs": [],
   "source": [
    "def conv_block(in_chan, out_chan, final_layer=False):\n",
    "    if not final_layer:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_chan, out_chan, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            #nn.InstanceNorm3d(out_chan),\n",
    "            nn.BatchNorm3d(out_chan),\n",
    "            nn.LeakyReLU(0.1))\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_chan, out_chan, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_chan))\n",
    "            #nn.InstanceNorm3d(out_chan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7VYWAI1RUudK"
   },
   "outputs": [],
   "source": [
    "class Skipnet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_chan, out_chan, filters):\n",
    "        super(Skipnet, self).__init__()\n",
    "\n",
    "        self.in_chan = in_chan\n",
    "        self.out_chan = out_chan\n",
    "        self.filters = filters\n",
    "\n",
    "        # Encoder\n",
    "        self.conv_1 = conv_block(self.in_chan, self.filters * 1)\n",
    "        self.conv_2 = conv_block(self.filters * 1, self.filters * 2)\n",
    "\n",
    "        self.conv1 = conv_block(filters * 1, filters * 1)\n",
    "        self.conv2 = conv_block(filters * 2, filters * 2)\n",
    "        self.max_pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Bottel-neck\n",
    "        self.bottel_neck = conv_block(self.filters * 2, self.filters * 4)\n",
    "        self.dropout = nn.Dropout3d(0.1)\n",
    "\n",
    "        # Decoder\n",
    "        self.upsample = nn.Upsample(scale_factor=(2.0, 2.0, 2.0), mode='nearest')\n",
    "        self.dconv_1 = conv_block(self.filters * 4, self.filters * 2)\n",
    "        self.dconv_2 = conv_block(self.filters * 2, self.filters * 1)\n",
    "\n",
    "        # Output and Conv_block\n",
    "        self.output = conv_block(self.filters * 1, self.out_chan, final_layer=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Down Sampling                                                 # if filters=16 then, \n",
    "        conv1 = self.conv1(self.conv_1(x))                                         # (:, 16, :, :, 16)\n",
    "        conv2 = self.conv2(self.conv_2(self.dropout(self.max_pool(conv1))))        # (:, 32, :, :, 8)\n",
    "\n",
    "        # Bottel-neck\n",
    "        bottelneck = self.bottel_neck(self.dropout(self.max_pool(conv2)))          # (:, 64, :, :, 4)\n",
    "\n",
    "        # Up Sampling\n",
    "        upconv1 = self.upsample(bottelneck)                                        # (:, 64, :, :, 8)\n",
    "        upconv1 = self.dconv_1(self.dropout(upconv1))                              # (:, 32, :, :, :)\n",
    "\n",
    "        upconv2 = self.upsample(upconv1)                                           # (:, 32, :, :, 16)\n",
    "        upconv2 = self.dconv_2(self.dropout(upconv2))                              # (:, 16, :, :, :)\n",
    "\n",
    "        out = self.output(upconv2)                                                 # (:, out_chan, :, :, 16)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Z5WJJTMdU3Ja"
   },
   "outputs": [],
   "source": [
    "class Unet3D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_chan, out_chan, filters):\n",
    "        super(Unet3D, self).__init__()\n",
    "\n",
    "        self.in_chan = in_chan\n",
    "        self.out_chan = out_chan\n",
    "        self.filters = filters\n",
    "\n",
    "        # Encoder\n",
    "        self.conv_1 = conv_block(self.in_chan, self.filters * 1)\n",
    "        self.conv_2 = conv_block(self.filters * 1, self.filters * 2)\n",
    "        self.conv_3 = conv_block(self.filters * 2, self.filters * 4)\n",
    "\n",
    "        self.conv1 = conv_block(filters * 1, filters * 1)\n",
    "        self.conv2 = conv_block(filters * 2, filters * 2)\n",
    "        self.conv3 = conv_block(filters * 4, filters * 4)\n",
    "\n",
    "        self.max_pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Bottel-neck\n",
    "        self.bottel_neck = conv_block(self.filters * 4, self.filters * 8)\n",
    "        self.dropout = nn.Dropout3d(0.1)\n",
    "\n",
    "        # Decoder\n",
    "        self.upsample = nn.Upsample(scale_factor=(2.0, 2.0, 2.0), mode='nearest')\n",
    "        self.skip1 = Skipnet(in_chan=filters*4, out_chan=filters*4, filters=16)\n",
    "        self.skip2 = Skipnet(in_chan=filters*2, out_chan=filters*2, filters=16)\n",
    "        self.skip3 = Skipnet(in_chan=filters*1, out_chan=filters*1, filters=16)\n",
    "        self.dconv_1 = conv_block(self.filters * 12, self.filters * 4)\n",
    "        self.dconv_2 = conv_block(self.filters * 6, self.filters * 2)\n",
    "        self.dconv_3 = conv_block(self.filters * 3, self.filters * 1)\n",
    "\n",
    "        # Output and Conv_block\n",
    "        self.output = conv_block(self.filters * 1, self.out_chan, final_layer=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Down Sampling\n",
    "        conv1 = self.conv1(self.conv_1(x))                                            # (:, 16, :, :, 16)\n",
    "        conv2 = self.conv2(self.conv_2(self.dropout(self.max_pool(conv1))))           # (:, 32, :, :, 8)\n",
    "        conv3 = self.conv3(self.conv_3(self.dropout(self.max_pool(conv2))))           # (:, 64, :, :, 4)\n",
    "\n",
    "        # Bottel-neck\n",
    "        bottelneck = self.bottel_neck(self.dropout(self.max_pool(conv3)))             # (:, 128, :, :, 2)\n",
    "\n",
    "        # Up Sampling\n",
    "        upconv1 = self.upsample(bottelneck)                                           # (:, 128, :, :, 4)\n",
    "        skip_1 = self.skip1(conv3)                                                    # (:, 64, :, :, 16)\n",
    "        upconv1 = torch.cat([upconv1, skip_1], dim=1)                                 # (:, 128+64, :, :, :)\n",
    "        upconv1 = self.dconv_1(self.dropout(upconv1))                                 # (:, 64, :, :, :)\n",
    "\n",
    "        upconv2 = self.upsample(upconv1)                                              # (:, 64, :, :, 8)\n",
    "        skip_2 = self.skip2(conv2)                                                    # (:, 32, :, :, 16)\n",
    "        upconv2 = torch.cat([upconv2, skip_2], dim=1)                                 # (:, 64+32, :, :, :)\n",
    "        upconv2 = self.dconv_2(self.dropout(upconv2))                                 # (:, 32, :, :, :)\n",
    "\n",
    "        upconv3 = self.upsample(upconv2)                                              # (:, 32, :, :, 16)\n",
    "        skip_3 = self.skip3(conv1)                                                    # (:, 16, :, :, 16)\n",
    "        upconv3 = torch.cat([upconv3, skip_3], dim=1)                                 # (:, 32+16, :, :, :)\n",
    "        upconv3 = self.dconv_3(self.dropout(upconv3))                                 # (:, 16, :, :, :)\n",
    "\n",
    "        out = torch.sigmoid(self.output(upconv3))                                     # (:, 1, :, :, 16)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jY0-9L-8U4Pn",
    "outputId": "b61544e4-0aee-466e-e25c-c6bfb5d40eec"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "    if isinstance(m, nn.BatchNorm3d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model = Unet3D(in_chan=1, out_chan=1, filters=16).to(device)\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R3SoRuE8U7VT"
   },
   "outputs": [],
   "source": [
    "#summary(model, (1, 192, 192, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu7lFrz5VyS4"
   },
   "source": [
    "### *Training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smxTho8lV7YZ"
   },
   "source": [
    "#### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eExdBqKuV6Rg"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "hist_train_loss = []\n",
    "hist_val_loss = []\n",
    "hist_train_dice = []\n",
    "hist_val_dice = []\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "PATH = './COVID-19-20/'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, axis=(2, 3, 4), epsilon=0.00001):\n",
    "    dice_numerator = (2.0 * torch.sum(y_pred * y_true, axis=axis)) + epsilon\n",
    "    dice_denominator = torch.sum(y_pred, dim=axis) + torch.sum(y_true, dim=axis) + epsilon\n",
    "    dice_coefficient = torch.mean(dice_numerator / dice_denominator)\n",
    "    return dice_coefficient\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred, axis=(2, 3, 4), epsilon=0.00001):\n",
    "    dice_numerator = (2.0 * torch.sum(y_pred * y_true, axis=axis)) + epsilon\n",
    "    dice_denominator = torch.sum(y_pred**2, dim=axis) + torch.sum(y_true**2, dim=axis) + epsilon\n",
    "    dice_loss = 1 - torch.mean(dice_numerator / dice_denominator)\n",
    "    return dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8L7XgNYZV_k6"
   },
   "source": [
    "#### Training Loop\n",
    "\n",
    "*  **optimizer.zero_grad(set_to_none=True)**\n",
    "    \n",
    "    *  instead of setting to zero, set the grads to None. This is will in general have lower memory footprint, and can modestly improve performance. However, it changes certain behaviors. For example: 1. When the user tries to access a gradient and perform manual ops on it, a None attribute or a Tensor full of 0s will behave differently. 2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads are guaranteed to be None for params that did not receive a gradient. 3. torch.optim optimizers have a different behavior if the gradient is 0 or None (in one case it does the step with a gradient of 0 and in the other it skips the step altogether)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvqyo5TxV6M8"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    num_train_sample = 0.0\n",
    "    num_val_sample = 0.0\n",
    "\n",
    "    dice_sum = 0.\n",
    "    dice_count = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        #optimizer.zero_grad()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = soft_dice_loss(labels, outputs)\n",
    "        loss.backward(retain_graph=False)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "        num_train_sample += inputs.size(0)\n",
    "        dice = dice_coefficient(labels, outputs)\n",
    "        dice_sum += dice\n",
    "        dice_count += 1\n",
    "    train_dice = dice_sum / dice_count\n",
    "    train_loss = train_loss / num_train_sample\n",
    "    hist_train_loss.append(train_loss)\n",
    "    hist_train_dice.append(train_dice)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dice_sum = 0.\n",
    "        dice_count = 0\n",
    "        for batch in tqdm(val_loader):\n",
    "            inputs = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = soft_dice_loss(labels, outputs)\n",
    "            val_loss += loss.item()*inputs.size(0)\n",
    "            num_val_sample += inputs.size(0)\n",
    "            dice = dice_coefficient(labels, outputs)\n",
    "            dice_sum += dice\n",
    "            dice_count += 1\n",
    "        val_dice = dice_sum / dice_count\n",
    "        val_loss = val_loss / num_val_sample\n",
    "        hist_val_loss.append(val_loss)\n",
    "        hist_val_dice.append(val_dice)\n",
    "\n",
    "    print(f'\\nEpoch: {epoch+1}: \\nTrain loss:      {train_loss}, \\tTrain Dice:      {train_dice}, \\nValidation loss: {val_loss}, \\tValidation Dice: {val_dice}')\n",
    "    print('Learning Rate:', {optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    if val_loss <= val_loss_min:\n",
    "        print(f'Validation loss is decreased from {val_loss_min} ---> {val_loss}.\\nSaving Model ...')\n",
    "        torch.save(model.state_dict(), PATH+'Unet3D_AutoEncoder_model.pth')\n",
    "        val_loss_min = val_loss\n",
    "\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'hist_train_loss': hist_train_loss,\n",
    "                'hist_val_loss': hist_val_loss,\n",
    "                'hist_train_dice': hist_train_dice,\n",
    "                'hist_val_dice': hist_val_dice,\n",
    "                'val_loss_min': val_loss_min},\n",
    "               PATH + 'Unet3D_AutoEncoder_model_checkpoints.pt')\n",
    "\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcTWJPH_zYCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djAaLy_t52rD"
   },
   "source": [
    "### *Training from checkpoints*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fFpVf_0JWZ6P"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(PATH + 'Unet3D_AutoEncoder_model_checkpoints.pt')\n",
    "\n",
    "epoch = checkpoint['epoch'] + 1\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "hist_train_loss = checkpoint['hist_train_loss']\n",
    "hist_val_loss = checkpoint['hist_val_loss']\n",
    "hist_train_dice = checkpoint['hist_train_dice']\n",
    "hist_val_dice = checkpoint['hist_val_dice']\n",
    "val_loss_min = checkpoint['val_loss_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJsJcI6QZGnC",
    "outputId": "8a356535-a9dd-479e-a81e-cf30b8dbcce6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eJPOKbDK59UD",
    "outputId": "8b7135a3-cae8-4bb2-ae7a-70c9ad559745"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [20:05<00:00, 15.07s/it]\n",
      "100%|██████████| 20/20 [02:04<00:00,  6.21s/it]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7: \n",
      "Train loss:      0.6898237600922584, \tTrain Dice:      0.16612032055854797, \n",
      "Validation loss: 0.7313506786639874, \tValidation Dice: 0.14454589784145355\n",
      "Learning Rate: {0.01}\n",
      "Validation loss is decreased from 0.733027763855763 ---> 0.7313506786639874.\n",
      "Saving Model ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [20:24<00:00, 15.30s/it]\n",
      "100%|██████████| 20/20 [01:58<00:00,  5.92s/it]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8: \n",
      "Train loss:      0.6796185404062272, \tTrain Dice:      0.17473052442073822, \n",
      "Validation loss: 0.7575683211668943, \tValidation Dice: 0.1276153177022934\n",
      "Learning Rate: {0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [19:26<00:00, 14.59s/it]\n",
      "100%|██████████| 20/20 [01:59<00:00,  5.97s/it]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9: \n",
      "Train loss:      0.6575667887926102, \tTrain Dice:      0.19324195384979248, \n",
      "Validation loss: 0.7839267865205423, \tValidation Dice: 0.119595967233181\n",
      "Learning Rate: {0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [19:40<00:00, 14.75s/it]\n",
      "100%|██████████| 20/20 [01:59<00:00,  6.00s/it]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10: \n",
      "Train loss:      0.6853767760097981, \tTrain Dice:      0.1830826848745346, \n",
      "Validation loss: 0.9138992627461752, \tValidation Dice: 0.046740513294935226\n",
      "Learning Rate: {0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [19:45<00:00, 14.82s/it]\n",
      "100%|██████████| 20/20 [01:59<00:00,  5.97s/it]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11: \n",
      "Train loss:      0.6928727746009826, \tTrain Dice:      0.17283180356025696, \n",
      "Validation loss: 0.7314542868198493, \tValidation Dice: 0.16831672191619873\n",
      "Learning Rate: {0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [19:26<00:00, 14.59s/it]\n",
      "100%|██████████| 20/20 [02:00<00:00,  6.01s/it]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12: \n",
      "Train loss:      0.6519338838756085, \tTrain Dice:      0.1992054134607315, \n",
      "Validation loss: 0.6927454395171924, \tValidation Dice: 0.17935971915721893\n",
      "Learning Rate: {0.01}\n",
      "Validation loss is decreased from 0.7313506786639874 ---> 0.6927454395171924.\n",
      "Saving Model ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [20:23<00:00, 15.30s/it]\n",
      "100%|██████████| 20/20 [02:04<00:00,  6.23s/it]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13: \n",
      "Train loss:      0.6626156479120254, \tTrain Dice:      0.1980482041835785, \n",
      "Validation loss: 0.7145175842138437, \tValidation Dice: 0.16964475810527802\n",
      "Learning Rate: {0.01}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [07:18<14:20, 16.24s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c1c2881ebb79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#optimizer.zero_grad(set_to_none=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_dice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e4ea3d22438d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mskip_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m                                                    \u001b[0;31m# (:, 16, :, :, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mupconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupconv3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                                 \u001b[0;31m# (:, 32+16, :, :, :)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mupconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdconv_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupconv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                                 \u001b[0;31m# (:, 16, :, :, :)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupconv3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                                     \u001b[0;31m# (:, 1, :, :, 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 288.00 MiB (GPU 0; 14.73 GiB total capacity; 13.07 GiB already allocated; 237.88 MiB free; 13.56 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "while epoch < epochs:\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    num_train_sample = 0.0\n",
    "    num_val_sample = 0.0\n",
    "\n",
    "    dice_sum = 0.\n",
    "    dice_count = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = soft_dice_loss(labels, outputs)\n",
    "        loss.backward(retain_graph=False)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "        num_train_sample += inputs.size(0)\n",
    "        dice = dice_coefficient(labels, outputs)\n",
    "        dice_sum += dice\n",
    "        dice_count += 1\n",
    "    train_dice = dice_sum / dice_count\n",
    "    train_loss = train_loss / num_train_sample\n",
    "    hist_train_loss.append(train_loss)\n",
    "    hist_train_dice.append(train_dice)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dice_sum = 0.\n",
    "        dice_count = 0\n",
    "        for batch in tqdm(val_loader):\n",
    "            inputs = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = soft_dice_loss(labels, outputs)\n",
    "            val_loss += loss.item()*inputs.size(0)\n",
    "            num_val_sample += inputs.size(0)\n",
    "            dice = dice_coefficient(labels, outputs)\n",
    "            dice_sum += dice\n",
    "            dice_count += 1\n",
    "        val_dice = dice_sum / dice_count\n",
    "        val_loss = val_loss / num_val_sample\n",
    "        hist_val_loss.append(val_loss)\n",
    "        hist_val_dice.append(val_dice)\n",
    "\n",
    "    print(f'\\nEpoch: {epoch+1}: \\nTrain loss:      {train_loss}, \\tTrain Dice:      {train_dice}, \\nValidation loss: {val_loss}, \\tValidation Dice: {val_dice}')\n",
    "    print('Learning Rate:', {optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    if val_loss <= val_loss_min:\n",
    "        print(f'Validation loss is decreased from {val_loss_min} ---> {val_loss}.\\nSaving Model ...')\n",
    "        torch.save(model.state_dict(), PATH+'Unet3D_AutoEncoder_model.pth')\n",
    "        val_loss_min = val_loss\n",
    "\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'hist_train_loss': hist_train_loss,\n",
    "                'hist_val_loss': hist_val_loss,\n",
    "                'hist_train_dice': hist_train_dice,\n",
    "                'hist_val_dice': hist_val_dice,\n",
    "                'val_loss_min': val_loss_min},\n",
    "               PATH + 'Unet3D_AutoEncoder_model_checkpoints.pt')\n",
    "\n",
    "    print()\n",
    "    scheduler.step(val_loss)\n",
    "    epoch += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6pLKLO2KUk9X",
    "jH1DKATBVs4h",
    "aXKbirCGUrfE",
    "smxTho8lV7YZ",
    "8L7XgNYZV_k6"
   ],
   "name": "Unet3D_AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
